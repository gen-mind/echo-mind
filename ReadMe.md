
<div align="center">

# EchoMind

### OpenClaw for Business ‚Äî With Zero Security Risk

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](license)
[![Deploy Anywhere](https://img.shields.io/badge/Deploy-Anywhere-brightgreen.svg)](#deployment-modes)

**The power of personal AI assistants like OpenClaw ‚Äî but for your entire organization.**<br/>
**Your company knowledge + your business tools. Fully sandboxed. Completely free.**

[Documentation](docs/architecture.md) ¬∑ [Why EchoMind?](#why-echomind) ¬∑ [OpenClaw vs EchoMind](#openclaw-vs-echomind)

</div>

---

## üß† What is it?

EchoMind brings the power of personal AI assistants to the enterprise ‚Äî **without the security nightmares**.

Like [OpenClaw](https://openclaw.ai/), EchoMind is an AI agent that can access your data, execute workflows, and automate tasks. But instead of running with unrestricted access on personal devices, EchoMind runs in **isolated, ephemeral sandboxes** with enterprise-grade authentication and permission controls.

**EchoMind connects to:**
- **Organizational knowledge** ‚Äî Teams, SharePoint, Google Drive, internal wikis, policies, and documents
- **Personal business tools** ‚Äî Email, calendar, CRM, and the apps your teams use daily

> See [63 Supported Connectors](docs/personal-assistant/echomind-connectors.md) ‚Äî including Salesforce, SAP, ServiceNow, Workday, and more.

**EchoMind is an AI agent** that **thinks** about what the workflow needs, **retrieves** the right internal context, **acts** using tools, then **verifies** the result ‚Äî all within a secure, permission-aware sandbox.

> Built for real work: support automation, IT deflection, meeting follow-ups, contract review,
> AP/invoice handling, onboarding, and any process where the bottleneck is "finding the right info + doing the next step".

## üîí Secure by Design ‚Äî Sandboxed Execution

Unlike personal AI assistants that run with full system access, EchoMind executes every workflow in an **ephemeral, isolated sandbox**:

| Security Feature | How It Works |
|------------------|--------------|
| **Ephemeral Sandboxes** | Each workflow runs in a fresh container that's destroyed after completion ‚Äî no state leaks between runs |
| **Delegated Authorization** | Sandboxes call your tools with user-scoped tokens; permissions enforced at every layer |
| **No Direct System Access** | Workflows can't execute arbitrary shell commands on your infrastructure |
| **Lease-Based Execution** | Exclusive access with TTL prevents runaway processes and resource exhaustion |
| **Air-Gap Ready** | Deploy fully disconnected ‚Äî no internet, no telemetry, no phone-home |

**The result:** Your teams get the productivity of an AI assistant. Your security team sleeps at night.

---

## ‚ö° AI in Minutes (Not Months)

**Skip procurement. Start building today.**

No budget approvals. No vendor negotiations.
Deploy EchoMind now and ship your first internal AI workflow this week.

---
### ü§ù Need help getting started? Let‚Äôs jump on a quick call (free)

If you want a fast setup review, architecture feedback, or help choosing the right deployment mode,
you can book a **free call** with the author.

üìÖ [**Book a free call**](https://calendar.app.google/QuNua7HxdsSasCGu9) with [gsantopaolo](https://github.com/gsantopaolo)
---
## ‚ú® How it works

```
üîÑ Think ‚Üí Act ‚Üí Observe ‚Üí Reflect ‚Üí Evaluate ‚Üí Answer
```

> The agent ü§î **thinks** about what information it needs, üë∑‚Äç‚ôÇÔ∏è **acts** by querying sources and tools, üîç **observes** the results, and ü§ñ **reflects** on whether it has enough context. Before responding, it ‚öñÔ∏è **evaluates** the quality and completeness of its answer ‚Äî looping back if needed ‚Äî then delivers a grounded üí¨ **answer**.
## ‚öôÔ∏è Automation Use Cases (Real-World Inspired)

EchoMind is built for *process automation*, not just Q&A:
**think ‚Üí act ‚Üí observe ‚Üí reflect ‚Üí evaluate ‚Üí answer**, with permission-aware answers and source-grounded output.

### üéß Customer Support Automation
- Deflect repetitive chats and tickets with grounded answers from your KB and policies
- Escalate only complex cases with full context + suggested replies

### üìù Meetings ‚Üí Actions ‚Üí Follow-ups ‚Üí CRM
- Generate meeting notes + action items
- Draft follow-up emails
- Save structured notes into your CRM (e.g., Salesforce)

### üß† ‚ÄúKnowledge Coach‚Äù for Frontline Teams
- Make staff dramatically faster at finding the right internal info
- Serve answers grounded in policies, research, and product docs

### üß∞ IT Helpdesk Ticket Deflection (Shift-Left)
- Resolve common issues without creating tickets
- Pre-fill tickets only when needed (device, logs, steps tried)

### ‚öñÔ∏è Contract Review Acceleration
- Extract key terms, flag risky clauses, summarize obligations
- Suggest redlines based on your playbooks and templates

### üßæ Accounts Payable Automation
- Invoice extraction + coding suggestions
- Approval routing + audit-ready explanations

> **Deep Dive:** [Business Use Cases](docs/personal-assistant/echomind-use-cases-business-problems.md) ‚Äî 4 productized solutions (SmartTicketing, DataInsight, OnboardingBot, CustomerContext360)
> | [Connector Use Cases](docs/personal-assistant/echomind-connector-use-cases.md) ‚Äî 79 real-world workflows across 37 connectors

## üöÄ Why EchoMind?

**Enterprise AI assistants without the enterprise price tag ‚Äî or the security risks.**

| Why It Matters | EchoMind Delivers |
|----------------|-------------------|
| **Free forever** | MIT licensed. $0. No usage caps. No "enterprise" tier. |
| **Secure by default** | Sandboxed execution, not "trust the user" security |
| **Your infrastructure** | Self-host on-prem, in your cloud, or air-gapped |
| **Your data stays yours** | No telemetry, no phone-home, no vendor lock-in |

---


## üß¨ What makes EchoMind agentic?
EchoMind is an **agentic RAG platform** that actually *thinks* before it retrieves ‚Äî and it‚Äôs **100% free (MIT)** üÜì.

- **Reasons** about what information it needs before retrieving
- **Plans** multi-step retrieval strategies across multiple data sources
- **Uses tools** to execute actions, call APIs, and process data
- **Remembers** context across conversations with short-term and long-term memory

---
 
## Key Features

| Feature | Description |
|---------|-------------|
| **Agentic Architecture** | Think ‚Üí Act ‚Üí Observe ‚Üí Reflect loop for intelligent retrieval |
| **Multi-Source Connectors** | [63 connectors](docs/personal-assistant/echomind-connectors.md) ‚Äî Salesforce, SAP, Teams, Drive, and more |
| **Flexible Deployment** | Cloud, Hybrid, or fully Air-Gapped (SCIF compliant) |
| **Private LLM Inference** | TGI/vLLM for on-premise GPU clusters |
| **Enterprise Auth** | Authentik with OIDC/LDAP/Active Directory support |
| **Per-User Vector Collections** | Scoped search across user, group, and organization data |


|                                   |                                                                             |
|-----------------------------------|-----------------------------------------------------------------------------|
| üîç **Multi-Step Retrieval**       | Goes beyond "retrieve-then-generate" ‚Äî reasons across multiple sources      |
| üè† **Private and SaaS LLM Ready** | Run with TGI/vLLM on your own GPU cluster or connected to your favorite LLM API |
| üîí **Air-Gap / SCIF Ready**       | No internet, no telemetry, no phone-home ‚Äî fully self-contained             |
| üì¶ **Deploy Anywhere**            | Single container to Kubernetes cluster ‚Äî your choice                        |
| üÜì **MIT Licensed ‚Äî Free Forever** | No paid tiers. No usage caps. No hidden licensing surprises |


---

## Architecture Overview

```mermaid
flowchart LR
    subgraph Clients
        C[Web / API / Bot]
    end

    subgraph EchoMind["EchoMind RAG Cluster"]
        API[API Gateway]
        AGENT[Agent Core<br/>Semantic Kernel]
        PROC[Doc Processing]

        subgraph Storage
            QDRANT[(Qdrant)]
            PG[(PostgreSQL)]
        end
    end

    subgraph Inference["Inference Cluster"]
        LLM[TGI/vLLM<br/>or Cloud APIs]
    end

    C --> AUTH --> API --> AGENT
    AGENT --> QDRANT
    AGENT --> LLM
    PROC --> QDRANT
    AGENT --> PG
```

For detailed architecture, see [docs/architecture.md](docs/architecture.md).

---

## Deployment Modes

EchoMind adapts to your security requirements:

| Mode | Description                                              | Use Case |
|------|----------------------------------------------------------|----------|
| **Cloud** | Deploy on your Could | Startups, teams without GPU infrastructure |
| **Hybrid** | Private RAG cluster + optional cloud LLM fallback        | Enterprises with sensitive data |
| **Air-Gapped** | Fully disconnected, zero external dependencies           | DoD, SCIF, classified networks |

### Air-Gapped / SCIF Compliance

EchoMind is designed for the most restricted environments:

- No internet access required
- No telemetry or phone-home capabilities
- All dependencies pre-packaged in container images
- Deployable to [Iron Bank (Platform One)](https://p1.dso.mil/iron-bank)
- LDAP/Active Directory integration via Authentik

---

### Deploy It Yourself ‚Äî or Let Us Deploy It for You

**Option 1: Self-Hosted** ‚Äî Deploy EchoMind anywhere you want on any GPU-equipped server. You own the hardware, you control the data. Follow the [quickstart guide](deployment/docker-cluster/QUICKSTART.md) and you're up in under an hour.

**Option 2: Fully Managed** ‚Äî We deploy and manage EchoMind on a **dedicated server exclusively for you** in our datacenter in **Germany (EU)**, fully **GDPR-compliant**. No shared infrastructure, no multi-tenancy ‚Äî your own machine, your own data.

At the **lowest price on the world wide web**:

#### 1‚Äì50 Users

| Spec | Details                                                                   |
|------|---------------------------------------------------------------------------|
| **CPU** | Intel Core i5-13500 (6P + 8E cores, Hyper-Threading)                      |
| **GPU** | NVIDIA RTX 4000 SFF Ada Generation ‚Äî **20 GB GDDR6 ECC**                  |
| **RAM** | 64 GB DDR4                                                                |
| **Storage** | 2 x 1.92 TB NVMe SSD (RAID 1)                                             |
| **Network** | 1 Gbit/s, unlimited traffic                                               |
| **Price** | **Starting at ~$450/month** - one time setup fee - Notthing else to pay - |

#### 50‚Äì200 Users

| Spec | Details                                                                         |
|------|---------------------------------------------------------------------------------|
| **CPU** | Intel Xeon Gold 5412U (24 cores, Hyper-Threading)                               |
| **GPU** | NVIDIA RTX PRO 6000 Blackwell Max-Q ‚Äî **96 GB GDDR7 ECC**, 5th-gen Tensor Cores |
| **RAM** | 256 GB DDR5 ECC (expandable to 768 GB)                                          |
| **Storage** | 2 x 960 GB NVMe SSD Datacenter Edition (RAID 1)                                 |
| **Network** | 1 Gbit/s guaranteed, unlimited traffic                                          |
| **Price** | **Starting at ~$1390/month** - one time setup fee -Notthing else to pay         |

> Both plans include: dedicated server setup, EchoMind deployment, SSL certificates, Authentik SSO configuration, and ongoing maintenance. No minimum contract ‚Äî cancel anytime.

üìÖ [**Book a free call**](https://calendar.app.google/QuNua7HxdsSasCGu9) to discuss your deployment with [gsantopaolo](https://github.com/gsantopaolo)

---

## Tech Stack

| Component | Technology | Notes |
|-----------|------------|-------|
| Agent Framework | [Semantic Kernel](https://github.com/microsoft/semantic-kernel) | Microsoft's AI orchestration SDK |
| Vector Database | [Qdrant](https://qdrant.tech/) | High-performance, Rust-based |
| LLM Inference | TGI / vLLM | Private GPU cluster support |
| Auth | [Authentik](https://goauthentik.io/) | Self-hosted OIDC provider |
| API | FastAPI + WebSocket | Async, streaming responses |
| Message Queue | NATS JetStream | Lightweight, persistent |
| Metadata DB | PostgreSQL | Reliable, JSONB support |
| Object Storage | MinIO / RustFS | S3-compatible (evaluating RustFS) |

---

## Project Structure

```
echomind/
‚îú‚îÄ‚îÄ docs/                    # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ architecture.md      # Technical architecture
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ agent/               # Semantic Kernel agent core
‚îÇ   ‚îú‚îÄ‚îÄ services/            # Background workers
‚îÇ   ‚îú‚îÄ‚îÄ connectors/          # Data source connectors
‚îÇ   ‚îú‚îÄ‚îÄ db/                  # Database clients
‚îÇ   ‚îî‚îÄ‚îÄ proto/               # Protocol Buffer definitions
‚îÇ       ‚îú‚îÄ‚îÄ public/          # API objects (client-facing)
‚îÇ       ‚îî‚îÄ‚îÄ internal/        # Internal service objects
‚îú‚îÄ‚îÄ deployment/
‚îÇ   ‚îú‚îÄ‚îÄ docker/              # Docker Compose files
‚îÇ   ‚îî‚îÄ‚îÄ k8s/                 # Kubernetes manifests
‚îú‚îÄ‚îÄ config/                  # Configuration files
‚îî‚îÄ‚îÄ tests/
```

> **Schema-First Development**: Proto definitions in `src/proto/` are the source of truth. CI generates TypeScript types (for clients) and Pydantic models (for Python) automatically.

---

## Contributing

We're building EchoMind in Python and welcome contributions in:

- **Backend**: FastAPI, async Python, gRPC
- **AI/ML**: Semantic Kernel, embeddings, reranking
- **Infrastructure**: Kubernetes, Docker, CI/CD
- **Connectors**: Microsoft Graph, Google APIs, and [60+ more](docs/personal-assistant/echomind-connectors.md)

---

## Documentation

- [Architecture](docs/architecture.md) - Technical design with Mermaid diagrams
- [Supported Connectors](docs/personal-assistant/echomind-connectors.md) - 63 data source integrations with market analysis
- [Business Use Cases](docs/personal-assistant/echomind-use-cases-business-problems.md) - Productized solutions for real business problems
- [Connector Use Cases](docs/personal-assistant/echomind-connector-use-cases.md) - 79 workflows showing what each connector enables
- [API Specification](docs/api-spec.md) - REST/WebSocket endpoint reference
- [Langfuse Setup](docs/langfuse-setup.md) - LLM observability and RAGAS evaluation

---

## OpenClaw vs EchoMind

[OpenClaw](https://openclaw.ai/) is an open-source personal AI assistant that runs locally with full system access ‚Äî shell commands, file operations, browser control. It's powerful for individuals, but [security researchers have flagged serious concerns](https://blogs.cisco.com/ai/personal-ai-agents-like-openclaw-are-a-security-nightmare) for organizational use: credential exposure, malicious skill injection, and no secure-by-default setup.

**EchoMind is OpenClaw for business** ‚Äî the same AI agent capabilities, redesigned for enterprise security:

| Capability | OpenClaw | EchoMind |
|------------|----------|----------|
| AI-powered workflows | Personal device | Isolated sandbox |
| System access | Unrestricted shell/files | Permission-controlled APIs |
| Data sources | Local files, messaging apps | Org knowledge + business tools |
| Security model | User responsibility | Enterprise-grade (OIDC, LDAP, air-gap) |
| Execution environment | Persistent on device | Ephemeral containers |
| Target use case | Personal productivity | Team/org automation |
| Cost | Free + API costs | Free (MIT) + API costs |

**Bottom line:** If you want an AI assistant for personal use, OpenClaw is excellent. If you want to deploy AI assistants across your organization without creating security vulnerabilities, EchoMind is built for that.

---

## Observability & Visualization

EchoMind includes a full observability stack covering infrastructure metrics, log aggregation, Gen AI evaluation, and vector visualization. All observability features are **optional** and gated by environment flags.

---

### Vector Visualization with TensorBoard

The **Projector Service** generates interactive 3D/2D visualizations of your vector collections using [TensorBoard Projector](https://projector.tensorflow.org/).

| Feature | Description |
|---------|-------------|
| **Collection Scoping** | Visualize vectors scoped to user (`user_{id}`), team (`team_{id}`), or organization (`org_{id}`) |
| **Search Filtering** | Optionally filter vectors by full-text search on title and content |
| **On-Demand Generation** | Trigger via API (`POST /api/v1/projector/generate`) or WebUI |
| **Batch Processing** | Fetches up to 20,000 vectors from Qdrant in batches of 500 |

**How it works:**
1. API receives a generation request with collection scope and optional search query
2. Request is published to NATS (`projector.generate`)
3. Projector worker fetches vectors from Qdrant, generates TensorFlow checkpoints + metadata
4. TensorBoard serves the visualization at `https://tensorboard.<DOMAIN>`

**Configuration:** `TENSORBOARD_DOMAIN`, `PROJECTOR_QDRANT_URL`, `PROJECTOR_LOG_DIR`

> See [Architecture](docs/architecture.md) for service interaction diagrams.

---

### Gen AI Observability with RAGAS and Langfuse

[Langfuse v3](https://langfuse.com/) provides **LLM observability** and [RAGAS](https://docs.ragas.io/) provides **RAG quality evaluation** ‚Äî giving you visibility into how well your AI is performing.

| Component | What It Does |
|-----------|-------------|
| **Langfuse Traces** | Records every chat interaction: query, response, context chunks, latency |
| **RAGAS Faithfulness** | Is the response grounded in the retrieved context? (0-1 score) |
| **RAGAS Response Relevancy** | Is the response relevant to the user's query? (0-1 score) |
| **RAGAS Context Precision** | Are the retrieved chunks relevant to the query? (0-1 score) |

**Two evaluation modes:**
- **Online (sampled)**: Configurable fraction of chat requests auto-evaluated (`RAGAS_SAMPLE_RATE`, default 10%)
- **Batch**: Admin-triggered evaluation of recent sessions via WebUI or API (`POST /api/v1/evaluate/batch`)

**Enabling:** Set `ENABLE_LANGFUSE=true` in `.env.host` and configure secrets. See [Langfuse Setup](docs/langfuse-setup.md).

Langfuse shares PostgreSQL, MinIO, and Redis with EchoMind. ClickHouse is dedicated to Langfuse for OLAP trace storage.

---

### Standard Observability with Grafana, Loki, Prometheus

The infrastructure observability stack provides metrics, logs, and dashboards ‚Äî all self-hosted with no external dependencies.

| Component | Purpose |
|-----------|---------|
| [**Prometheus**](https://prometheus.io/) | Metrics collection ‚Äî scrapes `/metrics` from all services every 10s |
| [**Loki**](https://grafana.com/oss/loki/) | Log aggregation ‚Äî collects container stdout via Alloy |
| [**Grafana**](https://grafana.com/oss/grafana/) | Dashboards ‚Äî 12 pre-shipped dashboards, Authentik SSO |
| [**Alloy**](https://grafana.com/docs/alloy/) | Log collector ‚Äî auto-discovers Docker containers |
| **Exporters** | cAdvisor (containers), node-exporter (host), postgres-exporter, nats-exporter |

**12 Pre-Shipped Grafana Dashboards:**

| Dashboard | What It Shows |
|-----------|---------------|
| EchoMind Overview | Service health, error rates, NATS queue depth |
| Loki Logs Explorer | Service log browser with level filtering and full-text search |
| RAGAS Evaluation | RAG quality score trends, distributions, evaluation rates |
| Docker Containers | Per-container CPU, memory, network I/O, restarts |
| Node Exporter | Host CPU, memory, disk, network interfaces |
| NATS Server | Connections, messages in/out, throughput |
| NATS JetStream | Stream/consumer message counts, pending, lag |
| Traefik | HTTP request rate, latency percentiles, error rates |
| PostgreSQL | Connections, transactions, locks, cache hit ratio |
| MinIO | Object storage capacity, S3 traffic, request latency |
| Qdrant | Vector DB collection stats, query performance |
| Loki (self-monitoring) | Ingestion rate, error rates |

**Enabling:** Set `ENABLE_OBSERVABILITY=true` in `.env.host`. Access Grafana at `https://grafana.<DOMAIN>`.

> OpenTelemetry compatibility: The stack uses Prometheus exposition format and Loki's log pipeline, both of which are OpenTelemetry-compatible. Services can be instrumented with OTel SDKs to push traces and metrics alongside the pull-based Prometheus scraping.

---

## License

MIT License - See [LICENSE](license) for details.
